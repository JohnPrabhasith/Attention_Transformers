{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgMDi1WCmfTMiocNI9Fl9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnPrabhasith/Attention_Transformers/blob/main/Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcLsPToy-257"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Attention*** is an essential component of neural network Transformers, which are driving the current excitement in Large Language Models and AI. Specifically, a Decoder-Only Transformer, illustrated below, is the foundation for the popular model **ChatGPT**."
      ],
      "metadata": {
        "id": "LY41VUWC--Np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model = 2, row_dim = 0, col_dim = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, token_encoding, mask = None):\n",
        "    q = self.W_q(token_encoding)\n",
        "    k = self.W_k(token_encoding)\n",
        "    v = self.W_v(token_encoding)\n",
        "\n",
        "    sims = torch.matmul(q, k.transpose(dim0 = self.row_dim, dim1 = self.col_dim))\n",
        "    scaled_sims = sims / torch.tensor(k.size(self.col_dim) ** 0.5)\n",
        "\n",
        "    if mask is not None:\n",
        "      scaled_sims = scaled_sims.masked_fill(mask = mask, value = -1e9)\n",
        "\n",
        "    attention_percents = F.softmax(scaled_sims, dim = self.col_dim)\n",
        "    attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "    return attention_scores\n"
      ],
      "metadata": {
        "id": "2vLRu-1f_EOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_matrix = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])"
      ],
      "metadata": {
        "id": "G8FLRoGsFzIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptsvp2VmGOWy",
        "outputId": "8ea1ce5b-05ac-4498-cf65-b7fb7a1d67fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e62bce9d170>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_self_attention = MaskedSelfAttention(d_model = 2, row_dim = 0, col_dim = 1)"
      ],
      "metadata": {
        "id": "dwKV8Rc3GSoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.tril(torch.ones(3,3))\n",
        "mask = (mask == 0)"
      ],
      "metadata": {
        "id": "8KssSQ8FGcEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84hUUYzjG1mj",
        "outputId": "fb7a5ddd-4471-4382-810c-b16d40a47fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_self_attention(encoding_matrix, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-afCN9cHACX",
        "outputId": "c20e0e61-19a4-422f-f081-d3c776ca3e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.0062,  0.6072],\n",
              "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_self_attention.W_q.weight.transpose(0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gXHCz1HRaC",
        "outputId": "dd64acf1-96f5-42bb-ca43-1bea341e795c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoder-Decoder Attention"
      ],
      "metadata": {
        "id": "rqevMIKhKBlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, d_model = 2, row_dim = 0, col_dim = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, encoding_for_q, encoding_for_v, encoding_for_k, mask=None):\n",
        "    q = self.W_q(encoding_for_q)\n",
        "    k = self.W_k(encoding_for_k)\n",
        "    v = self.W_v(encoding_for_v)\n",
        "\n",
        "    sims = torch.matmul(q, k.transpose(dim0 = self.row_dim, dim1 = self.col_dim))\n",
        "    scaled_sims = sims / torch.tensor(k.size(self.col_dim) ** 0.5)\n",
        "\n",
        "    if mask is not None:\n",
        "      scaled_sims = scaled_sims.masked_fill(mask = mask, value = -1e9)\n",
        "\n",
        "    attention_percents = F.softmax(scaled_sims, dim = self.col_dim)\n",
        "    attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "    return attention_scores\n"
      ],
      "metadata": {
        "id": "YySFt6NfNIqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_for_q = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "encoding_for_v = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "encoding_for_k = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGHHU0ZUN2QX",
        "outputId": "3232e5be-0303-477b-f76e-3ded7eee925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e62bce9d170>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention = Attention(d_model = 2, row_dim = 0, col_dim = 1)"
      ],
      "metadata": {
        "id": "Wt6hWMXqOATu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention(encoding_for_q, encoding_for_v, encoding_for_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJVrv-kZOQ7-",
        "outputId": "a69d8d88-c311-40a5-f146-68d8314513cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## MultiHead_Attention"
      ],
      "metadata": {
        "id": "DkwqZjM3OWHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model = 2, row_dim = 0, col_dim = 1, num_heads = 1):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "        [Attention(d_model, row_dim, col_dim) for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "    self.col_dim = col_dim\n",
        "    self.row_dim = row_dim\n",
        "\n",
        "  def forward(self, encoding_for_q, encoding_for_v, emcoding_for_k, mask = None):\n",
        "    return torch.cat([head(encoding_for_q, encoding_for_v, emcoding_for_k) for head in self.heads], dim = self.col_dim)\n"
      ],
      "metadata": {
        "id": "Er8hs1keOd5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QwMDzYHQAuu",
        "outputId": "bf9ff100-c023-4722-e8d1-16e3208c1fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e62bce9d170>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention = MultiHeadAttention(2,0,1,1)"
      ],
      "metadata": {
        "id": "rnTl0uXvQEMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head_attention(encoding_for_q, encoding_for_v, encoding_for_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKBGN7OCQObu",
        "outputId": "c35ad0e0-3308-4a1b-e5ca-d31712fcf6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSenS9vVQQCC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}